{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f8180c",
   "metadata": {},
   "source": [
    "### Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e469f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd53f62",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18725b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'schid', 'tchid', 'tchexper', 'absent', 'readscore', 'mathscore',\n",
       "       'totalscore', 'boy', 'white_asian', 'black', 'tchwhite', 'tchmasters',\n",
       "       'freelunch', 'schurban', 'schrural', 'small', 'regular', 'aide'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"star.xlsx\"\n",
    "df = pd.read_excel(path)  \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9a0bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tchexper\"] = df[\"tchexper\"].replace(\"\", np.nan)\n",
    "df = df.dropna(subset=[\"tchexper\"])\n",
    "df[\"tchexper\"] = pd.to_numeric(df[\"tchexper\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4211a",
   "metadata": {},
   "source": [
    "### a) Sample means by classroom type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b35e9a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Regular (no aide)': np.float64(918.0428927680798),\n",
       " 'Regular (with aide)': np.float64(918.5313890261987),\n",
       " 'Small': np.float64(931.9418872266973)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = {\n",
    "    \"Regular (no aide)\": df.loc[(df[\"regular\"] == 1) & (df[\"aide\"] == 0), \"totalscore\"].mean(),\n",
    "    \"Regular (with aide)\": df.loc[df[\"aide\"] == 1, \"totalscore\"].mean(),\n",
    "    \"Small\": df.loc[df[\"small\"] == 1, \"totalscore\"].mean()\n",
    "}\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6575028",
   "metadata": {},
   "source": [
    "### b) Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "437a33ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 11:46:43.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1m                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             totalscore   R-squared:                       0.007\n",
      "Model:                            OLS   Adj. R-squared:                  0.007\n",
      "Method:                 Least Squares   F-statistic:                     20.93\n",
      "Date:                Sat, 27 Sep 2025   Prob (F-statistic):           8.74e-10\n",
      "Time:                        11:46:43   Log-Likelihood:                -32963.\n",
      "No. Observations:                5766   AIC:                         6.593e+04\n",
      "Df Residuals:                    5763   BIC:                         6.595e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        918.0429      1.643    558.781      0.000     914.822     921.264\n",
      "small         13.8990      2.411      5.765      0.000       9.172      18.626\n",
      "aide           0.4885      2.318      0.211      0.833      -4.056       5.033\n",
      "==============================================================================\n",
      "Omnibus:                      391.428   Durbin-Watson:                   1.825\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              505.619\n",
      "Skew:                           0.622   Prob(JB):                    1.61e-110\n",
      "Kurtosis:                       3.746   Cond. No.                         3.67\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"small\", \"aide\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = df[\"totalscore\"]\n",
    "\n",
    "model_b = sm.OLS(y, X).fit()\n",
    "logger.info(model_b.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68152a6e",
   "metadata": {},
   "source": [
    "### c) Adding teacher experience (tchexper):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcaad660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 11:46:43.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             totalscore   R-squared:                       0.020\n",
      "Model:                            OLS   Adj. R-squared:                  0.020\n",
      "Method:                 Least Squares   F-statistic:                     39.86\n",
      "Date:                Sat, 27 Sep 2025   Prob (F-statistic):           1.73e-25\n",
      "Time:                        11:46:43   Log-Likelihood:                -32925.\n",
      "No. Observations:                5766   AIC:                         6.586e+04\n",
      "Df Residuals:                    5762   BIC:                         6.588e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        904.7212      2.228    406.071      0.000     900.354     909.089\n",
      "small         14.0061      2.395      5.847      0.000       9.310      18.702\n",
      "aide          -0.6006      2.306     -0.260      0.795      -5.122       3.921\n",
      "tchexper       1.4690      0.167      8.784      0.000       1.141       1.797\n",
      "==============================================================================\n",
      "Omnibus:                      389.793   Durbin-Watson:                   1.827\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              503.369\n",
      "Skew:                           0.620   Prob(JB):                    4.95e-110\n",
      "Kurtosis:                       3.746   Cond. No.                         37.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"small\", \"aide\", \"tchexper\"]]\n",
    "X = sm.add_constant(X)\n",
    "model_c = sm.OLS(y, X).fit()\n",
    "logger.info(model_c.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6727d2",
   "metadata": {},
   "source": [
    "### d) Add BOY, FREELUNCH, WHITE_ASIAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4def5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 11:46:43.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             totalscore   R-squared:                       0.102\n",
      "Model:                            OLS   Adj. R-squared:                  0.101\n",
      "Method:                 Least Squares   F-statistic:                     109.3\n",
      "Date:                Sat, 27 Sep 2025   Prob (F-statistic):          5.60e-131\n",
      "Time:                        11:46:43   Log-Likelihood:                -32673.\n",
      "No. Observations:                5766   AIC:                         6.536e+04\n",
      "Df Residuals:                    5759   BIC:                         6.541e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const         923.2498      3.121    295.822      0.000     917.132     929.368\n",
      "small          13.8960      2.294      6.059      0.000       9.400      18.392\n",
      "aide            0.6983      2.209      0.316      0.752      -3.633       5.029\n",
      "tchexper        1.1140      0.161      6.908      0.000       0.798       1.430\n",
      "boy           -14.0452      1.846     -7.610      0.000     -17.663     -10.427\n",
      "freelunch     -34.1170      2.064    -16.531      0.000     -38.163     -30.071\n",
      "white_asian    11.8373      2.211      5.354      0.000       7.503      16.171\n",
      "==============================================================================\n",
      "Omnibus:                      425.841   Durbin-Watson:                   1.827\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              561.961\n",
      "Skew:                           0.652   Prob(JB):                    9.37e-123\n",
      "Kurtosis:                       3.800   Cond. No.                         46.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"small\", \"aide\", \"tchexper\", \"boy\", \"freelunch\", \"white_asian\"]]\n",
    "X = sm.add_constant(X)\n",
    "model_d = sm.OLS(y, X).fit()\n",
    "logger.info(model_d.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37054d7c",
   "metadata": {},
   "source": [
    "### e) Add TCHWHITE, TCHMASTERS, SCHURBAN, SCHRURAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28166b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-27 11:47:53.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1m                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             totalscore   R-squared:                       0.106\n",
      "Model:                            OLS   Adj. R-squared:                  0.104\n",
      "Method:                 Least Squares   F-statistic:                     68.14\n",
      "Date:                Sat, 27 Sep 2025   Prob (F-statistic):          5.21e-132\n",
      "Time:                        11:47:53   Log-Likelihood:                -32662.\n",
      "No. Observations:                5766   AIC:                         6.535e+04\n",
      "Df Residuals:                    5755   BIC:                         6.542e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const         931.7553      3.940    236.482      0.000     924.031     939.479\n",
      "small          13.9803      2.302      6.072      0.000       9.467      18.494\n",
      "aide            1.0023      2.217      0.452      0.651      -3.343       5.348\n",
      "tchexper        1.1562      0.166      6.979      0.000       0.831       1.481\n",
      "boy           -14.0083      1.843     -7.602      0.000     -17.620     -10.396\n",
      "freelunch     -32.5325      2.126    -15.302      0.000     -36.700     -28.365\n",
      "white_asian    16.2326      2.780      5.838      0.000      10.782      21.683\n",
      "tchwhite       -7.6683      2.842     -2.698      0.007     -13.240      -2.097\n",
      "tchmasters     -3.5598      2.019     -1.763      0.078      -7.518       0.399\n",
      "schurban       -5.7499      2.858     -2.012      0.044     -11.353      -0.147\n",
      "schrural       -7.0061      2.559     -2.738      0.006     -12.022      -1.990\n",
      "==============================================================================\n",
      "Omnibus:                      431.245   Durbin-Watson:                   1.827\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              570.689\n",
      "Skew:                           0.657   Prob(JB):                    1.19e-124\n",
      "Kurtosis:                       3.807   Cond. No.                         56.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X = df[[\"small\", \"aide\", \"tchexper\", \"boy\", \"freelunch\", \"white_asian\",\n",
    "        \"tchwhite\", \"tchmasters\", \"schurban\", \"schrural\"]]\n",
    "X = sm.add_constant(X)\n",
    "model_e = sm.OLS(y, X).fit()\n",
    "logger.info(model_e.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bfbd93",
   "metadata": {},
   "source": [
    "### f) Discussion of the importance of previous points:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7473f07",
   "metadata": {},
   "source": [
    "- Adding controls like **tchexper**, **demographics**, and **school** characteristics helps isolate the **“treatment”** effect of small classes vs. aide from confounding factors.\n",
    "\n",
    "- If the coefficients on **small** and **aide** remain stable, it suggests ***random assignment worked well (balance across groups).***\n",
    "\n",
    "- If they shift, it means *selection* or *imbalance* affected raw estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fdbc8",
   "metadata": {},
   "source": [
    "### g) School fixed effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9479532e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m X = pd.get_dummies(df[\u001b[33m\"\u001b[39m\u001b[33mschid\u001b[39m\u001b[33m\"\u001b[39m], drop_first=\u001b[38;5;28;01mTrue\u001b[39;00m).join(X)\n\u001b[32m      4\u001b[39m X = sm.add_constant(X)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model_g = \u001b[43msm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m.fit()\n\u001b[32m      7\u001b[39m anova_lm(model_e, model_g)   \u001b[38;5;66;03m# compare with model (e)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:921\u001b[39m, in \u001b[36mOLS.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    918\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    919\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mAn exception will be raised in the next version.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    920\u001b[39m     warnings.warn(msg, ValueWarning)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_keys:\n\u001b[32m    924\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_keys.remove(\u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:746\u001b[39m, in \u001b[36mWLS.__init__\u001b[39m\u001b[34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    745\u001b[39m     weights = weights.squeeze()\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m nobs = \u001b[38;5;28mself\u001b[39m.exog.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    749\u001b[39m weights = \u001b[38;5;28mself\u001b[39m.weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:200\u001b[39m, in \u001b[36mRegressionModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mself\u001b[39m.pinv_wexog: Float64Array | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_attr.extend([\u001b[33m'\u001b[39m\u001b[33mpinv_wexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwendog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[39m, in \u001b[36mLikelihoodModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m missing = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     94\u001b[39m hasconst = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mhasconst\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                              \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[38;5;28mself\u001b[39m.data.k_constant\n\u001b[32m     98\u001b[39m \u001b[38;5;28mself\u001b[39m.exog = \u001b[38;5;28mself\u001b[39m.data.exog\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[39m, in \u001b[36mModel._handle_data\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     data = \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[39m, in \u001b[36mhandle_data\u001b[39m\u001b[34m(endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    672\u001b[39m     exog = np.asarray(exog)\n\u001b[32m    674\u001b[39m klass = handle_data_class_factory(endog, exog)\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m             \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\data.py:84\u001b[39m, in \u001b[36mModelData.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.orig_endog = endog\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m.orig_exog = exog\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28mself\u001b[39m.endog, \u001b[38;5;28mself\u001b[39m.exog = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_endog_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.const_idx = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hayka\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\data.py:509\u001b[39m, in \u001b[36mPandasData._convert_endog_exog\u001b[39m\u001b[34m(self, endog, exog)\u001b[39m\n\u001b[32m    507\u001b[39m exog = exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np.asarray(exog)\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endog.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPandas data cast to numpy dtype of object. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mCheck input data with np.asarray(data).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._convert_endog_exog(endog, exog)\n",
      "\u001b[31mValueError\u001b[39m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "X = df[[\"small\", \"aide\", \"tchexper\", \"boy\", \"freelunch\", \"white_asian\",\n",
    "        \"tchwhite\", \"tchmasters\", \"schurban\", \"schrural\"]]\n",
    "X = pd.get_dummies(df[\"schid\"], drop_first=True).join(X)\n",
    "X = sm.add_constant(X)\n",
    "model_g = sm.OLS(y, X).fit()\n",
    "\n",
    "anova_lm(model_e, model_g)   # compare with model (e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
